Ethics in Tech

Code of Ethics for any profession is crucial. The older I have gotten, the more and more gray the world has become. No longer are things black and white and clear. Perspectives from either side of a discussion can be well articulated and valid (in most cases) and unless you are entirely shut out to growth or learning from others, it is hard to always know which side of the line to stand on. I believe that is why a code of ethics is so important. It provides grounding and acts as a compass in the decision making process. The challenging bit is that the interpretation of the code of ethics is still up to the individual. 

Reading through the Code of Ethics and two articles, I feel both intrigued and concerned for where our society currently is. We have so much potential to make changes for the good of both the individual and the collective, not to mention the essential changes needing to be made to protect the planet. But it feels like we are at the mercy of the innovators and having to trust that their interpretation of principles like, "Approve software only if they have a well-founded belief that it is safe, meets specifications, passes appropriate tests, and does not diminish quality of life, diminish privacy or harm the environment," is one genuinely motivated by the well-being of the public. But what does well-being mean exactly? What does well-founded look like or making sure it does not diminish the quality of life? And who is defining these things?

The articles I chose to read were, "The cybersecurity risk of self-driving cars," and "Project Dragonfly, Google's censored search engine." In both articles, the topic of what is in the best interest of the public is addressed. But again, that feels pretty subjective. However, speaking from my own perspective, I do not agree with Google's attempts to condone any sort of censorship in order to gain business. To me, that feels unethical. Countries all have different laws and regulations but a business has, in theory, core values and a mission they operate under. Making justifications in order to gain business contradicts their stated mission, "to organize the world's information and make it universally accessible and useful." But on the flip side of that argument, is it better to provide millions with access to all of the information outside of what is being censored? Or is it better to have an "all or nothing" approach?

The topic of self-driving cars and the cybersecurity risks has always been a concern of mine. Even the most secure operations that claim to be hacker proof have ended up releasing public statements apologizing for breaches. Personally, I feel I would need to see some extremely compelling numbers before I would take the risk of being in a self-driving car. I have a harder time seeing how the impact for the greater good is being justified. I see the potential, but it still feels like we are a long ways off from the public being convinced of the safety of self-driving cars. When it comes to this topic too, I worry that the curiosity of those behind the technology and the desire to achieve such a feat can quickly cloud the judgement of what is actually in the best interest of our society. In both of these articles, there is a power dynamic and motivator that cannot be ignored. And when it comes to power and its effects, I am always going to be skeptical. It is why Code of Ethics exist. But the room for subjective interpretation is forever going to be a factor.